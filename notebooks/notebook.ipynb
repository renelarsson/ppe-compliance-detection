{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc8bbefc",
      "metadata": {
        "id": "fc8bbefc"
      },
      "source": [
        "# PPE Compliance Detection Project\n",
        "\n",
        "This notebook demonstrates the development of a deep learning model for detecting Personal Protective Equipment (PPE) compliance in construction environments. The goal is to classify images into multiple classes, including both compliant and non-compliant scenarios.\n",
        "\n",
        "## Project Overview\n",
        "- **Dataset**: Images of workers wearing or missing PPE (e.g., helmets, gloves, vests).\n",
        "- **Objective**: Build a model to detect PPE compliance and identify missing equipment.\n",
        "- **Approach**: Use transfer learning with a pre-trained MobileNetV2 model.\n",
        "\n",
        "## Steps\n",
        "1. Data Loading and Preprocessing\n",
        "2. Model Definition and Compilation\n",
        "3. Model Training with Callbacks\n",
        "4. Evaluation and Visualization\n",
        "5. Model Export for Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84dc695b",
      "metadata": {
        "id": "84dc695b"
      },
      "source": [
        "## Data Preparation and Cleaning\n",
        "\n",
        "In this section, we will prepare the dataset for training. This includes:\n",
        "- Applying data augmentation techniques to improve model generalization.\n",
        "- Normalizing the image data to ensure consistent input to the model.\n",
        "- Use generators to load data from directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df81745",
      "metadata": {
        "id": "2df81745"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ppe-compliance-detection/data/labels.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UM477LsiKlkz"
      },
      "id": "UM477LsiKlkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9caab06a",
      "metadata": {
        "id": "9caab06a"
      },
      "outputs": [],
      "source": [
        "# Load and Preprocess Data\n",
        "# Define paths to the dataset directories\n",
        "data_dir = '/content/ppe-compliance-detection/data'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Normalization for validation and test data\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Load data from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Correct target size??????\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8590c9ba",
      "metadata": {
        "id": "8590c9ba"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "In this section, we will:\n",
        "- Visualize the distribution of classes in the dataset.\n",
        "- Analyze the image dimensions and aspect ratios.\n",
        "- Identify any potential issues, such as class imbalance or missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e33a265b",
      "metadata": {
        "id": "e33a265b"
      },
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize class distribution\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "class_counts = train_generator.classes\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x=class_counts, palette='viridis')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class Labels')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(ticks=range(len(class_labels)), labels=class_labels, rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Analyze image dimensions\n",
        "image_shapes = [img.shape for img, _ in train_generator]\n",
        "heights = [shape[0] for shape in image_shapes]\n",
        "widths = [shape[1] for shape in image_shapes]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(heights, bins=20, alpha=0.7, label='Heights')\n",
        "plt.hist(widths, bins=20, alpha=0.7, label='Widths')\n",
        "plt.title('Image Dimensions Distribution')\n",
        "plt.xlabel('Pixels')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01606892",
      "metadata": {
        "id": "01606892"
      },
      "source": [
        "## Model Selection and Parameter Tuning\n",
        "\n",
        "In this section, we will:\n",
        "- Define the model architecture using transfer learning with MobileNetV2.\n",
        "- Compile the model with appropriate loss functions and metrics.\n",
        "- Tune hyperparameters such as learning rate, batch size, and number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02cf8be0",
      "metadata": {
        "id": "02cf8be0"
      },
      "outputs": [],
      "source": [
        "# Model Selection and Parameter Tuning\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers for classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "762ce824",
      "metadata": {
        "id": "762ce824"
      },
      "source": [
        "## Model Training with Callbacks\n",
        "In this section, we will:\n",
        "- Includes early stopping and model checkpointing.\n",
        "- Trains the model for up to 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66278cc8",
      "metadata": {
        "id": "66278cc8"
      },
      "outputs": [],
      "source": [
        "# Model Training with Callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='best_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20874db",
      "metadata": {
        "id": "a20874db"
      },
      "source": [
        "## Evaluation and Visualization:\n",
        "In this section, we will:\n",
        "- Plots training and validation accuracy/loss.\n",
        "- Evaluates the model on the test set and prints the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a9387c3",
      "metadata": {
        "id": "0a9387c3"
      },
      "outputs": [],
      "source": [
        "# Evaluation and Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aece0af2",
      "metadata": {
        "id": "aece0af2"
      },
      "source": [
        "## Model Export for Deployment:\n",
        "In this section, we will save the trained model as ppe_compliance_model.h5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c770eab4",
      "metadata": {
        "id": "c770eab4"
      },
      "outputs": [],
      "source": [
        "# Model Export for Deployment\n",
        "\n",
        "# Save the trained model\n",
        "model.save('ppe_compliance_model.h5')\n",
        "print(\"Model saved as 'ppe_compliance_model.h5'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ppe-compliance-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}