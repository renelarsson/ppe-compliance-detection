{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7cb6146",
   "metadata": {},
   "source": [
    "# Chest X-Ray Pneumonia — Transfer Learning Workflow (Colab Ready)\n",
    "\n",
    "This notebook follows the course tutorials and project criteria:\n",
    "- Uses transfer learning (EfficientNetB0) with proper preprocessing\n",
    "- Adds data augmentation and two-stage training (head training + fine-tuning)\n",
    "- Includes evaluation metrics beyond accuracy (precision, recall, ROC–AUC, confusion matrix)\n",
    "- Demonstrates reproducibility and clear inference steps\n",
    "\n",
    "If KaggleHub auth fails, a Kaggle CLI fallback is provided. Keep credentials out of source control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c09180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: install packages (Colab) and configure KaggleHub\n",
    "!pip -q install kagglehub tensorflow pillow numpy scikit-learn matplotlib --upgrade\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely paste your Kaggle API token for KaggleHub\n",
    "os.environ[\"KAGGLE_API_TOKEN\"] = getpass(\"Paste Kaggle API token: \")\n",
    "print(\"KAGGLE_API_TOKEN set:\", \"***\" if os.environ.get(\"KAGGLE_API_TOKEN\") else \"MISSING\")\n",
    "\n",
    "# Reproducibility\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset via KaggleHub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Resolve chest_xray root with train/val/test\n",
    "from pathlib import Path\n",
    "base = Path(path)\n",
    "candidates = [p for p in base.rglob(\"chest_xray\") if p.is_dir()]\n",
    "chest_xray_root = candidates[0] if candidates else base\n",
    "print(\"Using chest_xray_root:\", chest_xray_root)\n",
    "train_dir = chest_xray_root / \"train\"\n",
    "val_dir = chest_xray_root / \"val\"\n",
    "test_dir = chest_xray_root / \"test\"\n",
    "print(\"train:\", train_dir)\n",
    "print(\"val:\", val_dir)\n",
    "print(\"test:\", test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e78f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback: Kaggle CLI (uncomment if KaggleHub fails)\n",
    "# import json, os, pathlib\n",
    "# pathlib.Path(\"/root/.kaggle\").mkdir(parents=True, exist_ok=True)\n",
    "# with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "#     json.dump({\"username\": \"<username>\", \"key\": \"<key>\"}, f)\n",
    "# os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
    "# !pip -q install kaggle\n",
    "# !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p data\n",
    "# !unzip -q data/chest-xray-pneumonia.zip -d data\n",
    "# %ls -la data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637d4d0",
   "metadata": {},
   "source": [
    "# Build Datasets with Preprocessing and Augmentation\n",
    "\n",
    "We create `tf.data` pipelines for train/val/test. For EfficientNetB0, we use its `preprocess_input` function. We also apply light data augmentation to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf.data pipelines with EfficientNet preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    str(train_dir), image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary')\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    str(val_dir), image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    str(test_dir), image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary')\n",
    "\n",
    "# Augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1)\n",
    "], name=\"augmentation\")\n",
    "\n",
    "# Apply preprocess_input\n",
    "\n",
    "def prep(x, y):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = preprocess_input(x)  # EfficientNet-specific preprocessing\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(prep).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(prep).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(prep).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef44873",
   "metadata": {},
   "source": [
    "# Transfer Learning: Build EfficientNetB0 Model\n",
    "\n",
    "We use EfficientNetB0 pre-trained on ImageNet. First we freeze the base to train only the custom head. Augmentation is included as a layer before the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d56a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with augmentation + EfficientNetB0 base\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63599cd1",
   "metadata": {},
   "source": [
    "# Stage 1 Training (Head Only)\n",
    "\n",
    "Train the classification head while keeping the EfficientNetB0 base frozen. Monitor training and validation curves to ensure convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train head\n",
    "EPOCHS_HEAD = 5\n",
    "history_head = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_head.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_head.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend(); plt.title('Accuracy (Head)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_head.history['loss'], label='Train Loss')\n",
    "plt.plot(history_head.history['val_loss'], label='Val Loss')\n",
    "plt.legend(); plt.title('Loss (Head)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fe33f",
   "metadata": {},
   "source": [
    "# Stage 2 Fine-Tuning (Unfreeze Top Layers)\n",
    "\n",
    "Unfreeze the top layers of EfficientNetB0 and continue training with a lower learning rate to improve performance without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze top layers and fine-tune\n",
    "# Unfreeze last N layers of the base model\n",
    "N = 50\n",
    "for layer in base_model.layers[-N:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "EPOCHS_FT = 5\n",
    "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FT)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_ft.history['accuracy'], label='Train Acc (FT)')\n",
    "plt.plot(history_ft.history['val_accuracy'], label='Val Acc (FT)')\n",
    "plt.legend(); plt.title('Accuracy (Fine-tune)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_ft.history['loss'], label='Train Loss (FT)')\n",
    "plt.plot(history_ft.history['val_loss'], label='Val Loss (FT)')\n",
    "plt.legend(); plt.title('Loss (Fine-tune)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b0ab7",
   "metadata": {},
   "source": [
    "# Evaluation: Accuracy, Precision, Recall, ROC–AUC, Confusion Matrix\n",
    "\n",
    "We evaluate the fine-tuned model on the test set and compute additional metrics commonly used in medical imaging tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and compute metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Standard evaluation\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print({\"test_loss\": float(test_loss), \"test_acc\": float(test_acc)})\n",
    "\n",
    "# Collect y_true and y_pred_proba\n",
    "y_true = []\n",
    "y_pred_proba = []\n",
    "for x_batch, y_batch in test_ds:\n",
    "    probs = model.predict(x_batch, verbose=0).ravel()\n",
    "    y_pred_proba.extend(probs.tolist())\n",
    "    y_true.extend(y_batch.numpy().ravel().tolist())\n",
    "\n",
    "y_true = np.array(y_true).astype(int)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "prec = precision_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, y_pred_proba)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print({\n",
    "    \"precision\": float(prec),\n",
    "    \"recall\": float(rec),\n",
    "    \"f1\": float(f1),\n",
    "    \"roc_auc\": float(auc)\n",
    "})\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2047a2",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "We demonstrate inference on a single image. The same preprocessing pipeline is applied before prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10829c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-image inference example\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Use one image from test_dir for demo\n",
    "sample_candidates = list(Path(test_dir).rglob(\"*.jpeg\")) + list(Path(test_dir).rglob(\"*.jpg\")) + list(Path(test_dir).rglob(\"*.png\"))\n",
    "assert len(sample_candidates) > 0, \"No sample images found in test_dir\"\n",
    "sample_image_path = str(sample_candidates[0])\n",
    "print(\"Sample:\", sample_image_path)\n",
    "\n",
    "img = image.load_img(sample_image_path, target_size=(224, 224))\n",
    "arr = image.img_to_array(img)\n",
    "arr = preprocess_input(arr)  # EfficientNet preprocessing\n",
    "arr = np.expand_dims(arr, axis=0)\n",
    "\n",
    "proba = float(model.predict(arr)[0][0])\n",
    "pred_label = \"Pneumonia\" if proba >= 0.5 else \"Normal\"\n",
    "print({\"label\": pred_label, \"score\": proba})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c008f0a",
   "metadata": {},
   "source": [
    "# Save Model Artifact\n",
    "\n",
    "We save the trained Keras model as an `.h5` file that can be loaded by the FastAPI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and (in Colab) download\n",
    "model.save(\"pneumonia_model.h5\")\n",
    "print(\"Saved: pneumonia_model.h5\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(\"pneumonia_model.h5\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28765800",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "We inspect class distribution and visualize sample images to understand dataset characteristics and potential imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution and sample visualization\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = []\n",
    "counts = []\n",
    "for cls in sorted([d.name for d in Path(train_dir).iterdir() if d.is_dir()]):\n",
    "    classes.append(cls)\n",
    "    counts.append(len(list((Path(train_dir)/cls).glob(\"*.*\"))))\n",
    "\n",
    "print({\"classes\": classes, \"train_counts\": counts})\n",
    "\n",
    "# Show grid of sample images\n",
    "def show_samples(root, cls, n=8):\n",
    "    files = list((Path(root)/cls).glob(\"*.*\"))[:n]\n",
    "    cols = 4\n",
    "    rows = (len(files) + cols - 1) // cols\n",
    "    plt.figure(figsize=(12, 3*rows))\n",
    "    for i, fp in enumerate(files):\n",
    "        img = tf.keras.utils.load_img(fp)\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(cls)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if classes:\n",
    "    show_samples(train_dir, classes[0], n=8)\n",
    "    if len(classes) > 1:\n",
    "        show_samples(train_dir, classes[1], n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "import pandas as pd\n",
    "\n",
    "def check_missing_values(directory):\n",
    "    missing_counts = {}\n",
    "    for cls in sorted([d.name for d in Path(directory).iterdir() if d.is_dir()]):\n",
    "        cls_dir = Path(directory) / cls\n",
    "        for img_file in cls_dir.glob(\"*.*\"):\n",
    "            try:\n",
    "                img = tf.keras.utils.load_img(img_file)\n",
    "            except Exception as e:\n",
    "                missing_counts[img_file.name] = str(e)\n",
    "    return missing_counts\n",
    "\n",
    "missing_values = check_missing_values(train_dir)\n",
    "if missing_values:\n",
    "    print(\"Missing or corrupted files detected:\")\n",
    "    for file, error in missing_values.items():\n",
    "        print(f\"{file}: {error}\")\n",
    "else:\n",
    "    print(\"No missing or corrupted files detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d75ca",
   "metadata": {},
   "source": [
    "# Dataset Variants for Different Models\n",
    "\n",
    "We build three dataset variants to match model preprocessing:\n",
    "- Baseline CNN: normalize to [0,1]\n",
    "- EfficientNetB0: `efficientnet.preprocess_input`\n",
    "- ResNet50V2: `resnet_v2.preprocess_input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build raw datasets and mapped variants\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_prep\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_prep\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "raw_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    str(train_dir), image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary')\n",
    "raw_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    str(val_dir), image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary')\n",
    "raw_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    str(test_dir), image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary')\n",
    "\n",
    "# Baseline normalization\n",
    "baseline_norm = lambda x, y: (tf.cast(x, tf.float32)/255.0, y)\n",
    "\n",
    "train_baseline = raw_train.map(baseline_norm).prefetch(tf.data.AUTOTUNE)\n",
    "val_baseline = raw_val.map(baseline_norm).prefetch(tf.data.AUTOTUNE)\n",
    "test_baseline = raw_test.map(baseline_norm).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# EfficientNet preprocessing\n",
    "train_eff = raw_train.map(lambda x,y: (eff_prep(tf.cast(x, tf.float32)), y)).prefetch(tf.data.AUTOTUNE)\n",
    "val_eff = raw_val.map(lambda x,y: (eff_prep(tf.cast(x, tf.float32)), y)).prefetch(tf.data.AUTOTUNE)\n",
    "test_eff = raw_test.map(lambda x,y: (eff_prep(tf.cast(x, tf.float32)), y)).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ResNet50V2 preprocessing\n",
    "train_resnet = raw_train.map(lambda x,y: (resnet_prep(tf.cast(x, tf.float32)), y)).prefetch(tf.data.AUTOTUNE)\n",
    "val_resnet = raw_val.map(lambda x,y: (resnet_prep(tf.cast(x, tf.float32)), y)).prefetch(tf.data.AUTOTUNE)\n",
    "test_resnet = raw_test.map(lambda x,y: (resnet_prep(tf.cast(x, tf.float32)), y)).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15330d5d",
   "metadata": {},
   "source": [
    "# Callbacks and Checkpointing\n",
    "\n",
    "We define reusable callbacks for early stopping, learning rate reduction, and model checkpointing. Best models are stored under the `artifacts/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks helper\n",
    "import os\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "def build_callbacks(name: str, monitor: str = 'val_accuracy'):\n",
    "    ckpt_path = f'artifacts/best_{name}.h5'\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=monitor, patience=3, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=monitor, factor=0.5, patience=2, min_lr=1e-6),\n",
    "        ModelCheckpoint(ckpt_path, monitor=monitor, save_best_only=True, save_weights_only=False)\n",
    "    ]\n",
    "    return callbacks, ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95314c96",
   "metadata": {},
   "source": [
    "# EfficientNetB0 Training with Callbacks\n",
    "\n",
    "We compile the model with accuracy and AUC, then train with callbacks to capture the best checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b291dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with AUC and train with callbacks\n",
    "from tensorflow.keras.metrics import AUC\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', AUC(name='auc')])\n",
    "\n",
    "callbacks, ckpt_eff_head = build_callbacks('efficientnet_head', monitor='val_auc')\n",
    "EPOCHS_HEAD = 5\n",
    "history_head = model.fit(train_eff, validation_data=val_eff, epochs=EPOCHS_HEAD, callbacks=callbacks)\n",
    "\n",
    "# Fine-tune\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy', AUC(name='auc')])\n",
    "\n",
    "callbacks_ft, ckpt_eff_ft = build_callbacks('efficientnet_ft', monitor='val_auc')\n",
    "EPOCHS_FT = 5\n",
    "history_ft = model.fit(train_eff, validation_data=val_eff, epochs=EPOCHS_FT, callbacks=callbacks_ft)\n",
    "\n",
    "print('EfficientNet checkpoints:', ckpt_eff_head, ckpt_eff_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84f4f2",
   "metadata": {},
   "source": [
    "# Baseline CNN Model\n",
    "\n",
    "We train a simple CNN as a baseline, using [0,1] normalization. Callbacks help capture the best performing checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56183323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build, train, evaluate baseline CNN\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "baseline = models.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    layers.Conv2D(32, 3, activation='relu'), layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'), layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu'), layers.MaxPooling2D(),\n",
    "    layers.Flatten(), layers.Dense(128, activation='relu'), layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "baseline.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', AUC(name='auc')])\n",
    "\n",
    "callbacks_bl, ckpt_bl = build_callbacks('baseline_cnn', monitor='val_auc')\n",
    "hist_bl = baseline.fit(train_baseline, validation_data=val_baseline, epochs=5, callbacks=callbacks_bl)\n",
    "loss_bl, acc_bl, auc_bl = baseline.evaluate(test_baseline)\n",
    "print({'baseline': {'loss': float(loss_bl), 'acc': float(acc_bl), 'auc': float(auc_bl)}, 'ckpt': ckpt_bl})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200559a",
   "metadata": {},
   "source": [
    "# ResNet50V2 Transfer Learning\n",
    "\n",
    "We build a ResNet50V2 transfer model with a custom head, trained on the ResNet-preprocessed datasets. We include callbacks and a short fine-tuning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfa6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build, train, evaluate ResNet50V2\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "resnet_base = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "resnet_base.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = resnet_base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "resnet_model = models.Model(inputs, outputs)\n",
    "\n",
    "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', AUC(name='auc')])\n",
    "cb_resnet_head, ckpt_resnet_head = build_callbacks('resnet_head', monitor='val_auc')\n",
    "hist_resnet_head = resnet_model.fit(train_resnet, validation_data=val_resnet, epochs=5, callbacks=cb_resnet_head)\n",
    "\n",
    "# Fine-tune top layers\n",
    "for layer in resnet_base.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "resnet_model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy', AUC(name='auc')])\n",
    "cb_resnet_ft, ckpt_resnet_ft = build_callbacks('resnet_ft', monitor='val_auc')\n",
    "hist_resnet_ft = resnet_model.fit(train_resnet, validation_data=val_resnet, epochs=5, callbacks=cb_resnet_ft)\n",
    "\n",
    "loss_r, acc_r, auc_r = resnet_model.evaluate(test_resnet)\n",
    "print({'resnet': {'loss': float(loss_r), 'acc': float(acc_r), 'auc': float(auc_r)}, 'ckpts': [ckpt_resnet_head, ckpt_resnet_ft]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b35924d",
   "metadata": {},
   "source": [
    "# Save and Reload Best Models & Histories\n",
    "\n",
    "We save training histories to JSON and demonstrate loading the best checkpoints for inference or further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save histories to JSON and reload checkpoints\n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save histories\n",
    "with open('artifacts/history_efficientnet_head.json', 'w') as f: json.dump(history_head.history, f)\n",
    "with open('artifacts/history_efficientnet_ft.json', 'w') as f: json.dump(history_ft.history, f)\n",
    "with open('artifacts/history_baseline.json', 'w') as f: json.dump(hist_bl.history, f)\n",
    "with open('artifacts/history_resnet_head.json', 'w') as f: json.dump(hist_resnet_head.history, f)\n",
    "with open('artifacts/history_resnet_ft.json', 'w') as f: json.dump(hist_resnet_ft.history, f)\n",
    "\n",
    "# Reload best models\n",
    "eff_best = load_model('artifacts/best_efficientnet_ft.h5') if os.path.exists('artifacts/best_efficientnet_ft.h5') else None\n",
    "bl_best = load_model('artifacts/best_baseline_cnn.h5') if os.path.exists('artifacts/best_baseline_cnn.h5') else None\n",
    "res_best = load_model('artifacts/best_resnet_ft.h5') if os.path.exists('artifacts/best_resnet_ft.h5') else None\n",
    "\n",
    "print({'loaded': {'efficientnet_ft': eff_best is not None, 'baseline': bl_best is not None, 'resnet_ft': res_best is not None}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d9db3",
   "metadata": {},
   "source": [
    "# Results Comparison Table\n",
    "\n",
    "We aggregate the key metrics across baseline CNN, EfficientNetB0 (fine-tuned), and ResNet50V2 (fine-tuned) for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comparison table\n",
    "import pandas as pd\n",
    "\n",
    "# EfficientNet metrics (reuse last eval with test_eff)\n",
    "loss_eff, acc_eff, auc_eff = model.evaluate(test_eff)\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\"model\": \"Baseline CNN\", \"acc\": acc_bl, \"auc\": auc_bl, \"loss\": loss_bl},\n",
    "    {\"model\": \"EfficientNetB0 (FT)\", \"acc\": acc_eff, \"auc\": auc_eff, \"loss\": loss_eff},\n",
    "    {\"model\": \"ResNet50V2 (FT)\", \"acc\": acc_r, \"auc\": auc_r, \"loss\": loss_r},\n",
    "])\n",
    "results = results.sort_values(by=[\"auc\", \"acc\"], ascending=False)\n",
    "print(results)\n",
    "results.to_csv('artifacts/results_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
